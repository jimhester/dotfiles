#!/usr/bin/env -S uv run --script
# /// script
# requires-python = ">=3.12"
# dependencies = ["nltk"]
# ///
"""Sample a user's GitHub comments from a repository and sort them by tone.

Uses the `gh` CLI for authenticated GitHub API access and NLTK's VADER
sentiment analyzer for tone classification.  VADER understands negation
("not great"), intensifiers ("EXTREMELY good"), capitalization, punctuation
emphasis ("nice!!!"), and emoji.

Run with uv (dependencies are resolved automatically):
    uv run gh-tone-analyzer owner/repo [--user USER] [--limit N] [--verbose]

Examples:
    uv run gh-tone-analyzer tidyverse/dplyr --user hadley
    uv run gh-tone-analyzer rust-lang/rust --user dtolnay --limit 50
    uv run gh-tone-analyzer myorg/myrepo --verbose
"""

import argparse
import json
import re
import subprocess
import sys
import textwrap
from collections import defaultdict
from dataclasses import dataclass

import nltk
from nltk.sentiment.vader import SentimentIntensityAnalyzer

nltk.download("vader_lexicon", quiet=True)
_vader = SentimentIntensityAnalyzer()

# -- Tone definitions --------------------------------------------------------

TONES = {
    "very positive":  {"description": "Strong approval, gratitude, or enthusiasm",  "threshold": (0.5, None)},
    "positive":       {"description": "Mild approval, agreement, or encouragement", "threshold": (0.05, 0.5)},
    "neutral":        {"description": "Factual, informational, or balanced",        "threshold": (-0.05, 0.05)},
    "negative":       {"description": "Mild concern, disagreement, or criticism",   "threshold": (-0.5, -0.05)},
    "very negative":  {"description": "Strong disagreement, frustration, or alarm", "threshold": (None, -0.5)},
}

TONE_ORDER = ["very positive", "positive", "neutral", "negative", "very negative"]

TONE_COLORS = {
    "very positive": "\033[1;32m",  # bold green
    "positive":      "\033[32m",    # green
    "neutral":       "\033[37m",    # white/gray
    "negative":      "\033[33m",    # yellow
    "very negative": "\033[31m",    # red
}
RESET = "\033[0m"
BOLD = "\033[1m"
DIM = "\033[2m"


# -- Data structures ----------------------------------------------------------


@dataclass
class Comment:
    body: str
    url: str
    created_at: str
    source: str  # "issue", "review", or "commit"
    context: str  # issue/PR title or number
    tone: str = ""
    compound: float = 0.0
    pos: float = 0.0
    neg: float = 0.0
    neu: float = 0.0


# -- GitHub API ---------------------------------------------------------------


def gh_api(endpoint: str, paginate: bool = True) -> list[dict]:
    """Call the GitHub API via the `gh` CLI."""
    cmd = ["gh", "api", endpoint, "--jq", ".[]"]
    if paginate:
        cmd.append("--paginate")
    try:
        result = subprocess.run(cmd, capture_output=True, text=True, check=True)
    except FileNotFoundError:
        print("Error: `gh` CLI not found. Install it from https://cli.github.com/", file=sys.stderr)
        sys.exit(1)
    except subprocess.CalledProcessError as e:
        print(f"Error calling GitHub API ({endpoint}):\n{e.stderr.strip()}", file=sys.stderr)
        sys.exit(1)

    # gh --jq '.[]' outputs one JSON object per line
    items = []
    for line in result.stdout.strip().splitlines():
        if line:
            try:
                items.append(json.loads(line))
            except json.JSONDecodeError:
                continue
    return items


def fetch_comments(repo: str, user: str | None, limit: int) -> list[Comment]:
    """Fetch issue comments, PR review comments, and commit comments."""
    comments: list[Comment] = []

    sources = [
        (f"/repos/{repo}/issues/comments", "issue"),
        (f"/repos/{repo}/pulls/comments", "review"),
        (f"/repos/{repo}/comments", "commit"),
    ]

    for endpoint, source in sources:
        params = "?sort=created&direction=desc&per_page=100"
        raw = gh_api(endpoint + params)

        for item in raw:
            author = (item.get("user") or {}).get("login", "")
            if user and author.lower() != user.lower():
                continue

            body = item.get("body", "") or ""
            if not body.strip():
                continue

            html_url = item.get("html_url", "")
            created = item.get("created_at", "")[:10]

            # Derive context (issue/PR number) from the URL
            context = ""
            if html_url:
                m = re.search(r"/(issues|pull)/(\d+)", html_url)
                if m:
                    context = f"#{m.group(2)}"

            comments.append(Comment(
                body=body,
                url=html_url,
                created_at=created,
                source=source,
                context=context,
            ))

        if len(comments) >= limit:
            break

    return comments[:limit]


# -- Tone analysis ------------------------------------------------------------


def classify(compound: float) -> str:
    """Map a VADER compound score to a tone label."""
    if compound >= 0.5:
        return "very positive"
    if compound >= 0.05:
        return "positive"
    if compound > -0.05:
        return "neutral"
    if compound > -0.5:
        return "negative"
    return "very negative"


def analyze_tone(comment: Comment) -> Comment:
    """Classify a comment's tone using VADER sentiment analysis."""
    scores = _vader.polarity_scores(comment.body)
    comment.compound = scores["compound"]
    comment.pos = scores["pos"]
    comment.neg = scores["neg"]
    comment.neu = scores["neu"]
    comment.tone = classify(comment.compound)
    return comment


# -- Display ------------------------------------------------------------------


def truncate(text: str, width: int = 120) -> str:
    """Collapse whitespace and truncate text to a single line."""
    collapsed = re.sub(r"\s+", " ", text).strip()
    if len(collapsed) <= width:
        return collapsed
    return collapsed[: width - 1] + "…"


def print_results(comments: list[Comment], verbose: bool, use_color: bool) -> None:
    """Print comments grouped and sorted by tone."""
    grouped: dict[str, list[Comment]] = defaultdict(list)
    for c in comments:
        grouped[c.tone].append(c)

    # Sort each group by compound score (most extreme first)
    for tone in grouped:
        grouped[tone].sort(key=lambda c: abs(c.compound), reverse=True)

    total = len(comments)
    avg = sum(c.compound for c in comments) / total
    print()
    header = f"Analyzed {total} comment{'s' if total != 1 else ''} — average sentiment: {avg:+.2f}"
    print(f"{BOLD}{header}{RESET}" if use_color else header)
    print()

    # Summary bar
    print("Distribution:")
    for tone in TONE_ORDER:
        count = len(grouped.get(tone, []))
        if count == 0:
            continue
        pct = count / total * 100
        bar_len = int(pct / 2)
        bar = "\u2588" * bar_len
        color = TONE_COLORS[tone] if use_color else ""
        reset = RESET if use_color else ""
        label = f"  {tone:<16s} {color}{bar} {count} ({pct:.0f}%){reset}"
        print(label)
    print()

    # Detailed listing
    for tone in TONE_ORDER:
        group = grouped.get(tone, [])
        if not group:
            continue

        color = TONE_COLORS[tone] if use_color else ""
        reset = RESET if use_color else ""
        bold = BOLD if use_color else ""
        dim = DIM if use_color else ""

        desc = TONES[tone]["description"]
        print(f"{bold}{color}\u2500\u2500 {tone.upper()} ({len(group)}) \u2500 {desc}{reset}")
        print()

        for c in group:
            source_tag = f"[{c.source}]"
            context_tag = f" {c.context}" if c.context else ""
            score_tag = f"compound={c.compound:+.2f}"
            meta = f"{dim}{c.created_at} {source_tag}{context_tag}  {score_tag}{reset}"
            print(f"  {meta}")

            body_preview = truncate(c.body)
            print(f"  {body_preview}")

            if verbose:
                print(f"  {dim}pos={c.pos:.2f}  neg={c.neg:.2f}  neu={c.neu:.2f}{reset}")

            if c.url:
                print(f"  {dim}{c.url}{reset}")
            print()

        print()


# -- Main ---------------------------------------------------------------------


def main():
    parser = argparse.ArgumentParser(
        description="Sample a user's GitHub comments and sort them by tone.",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=textwrap.dedent("""\
            examples:
              %(prog)s tidyverse/dplyr --user hadley
              %(prog)s rust-lang/rust --user dtolnay --limit 50
              %(prog)s myorg/myrepo --verbose
        """),
    )
    parser.add_argument("repo", help="GitHub repository (owner/repo)")
    parser.add_argument(
        "--user", "-u",
        help="GitHub username to filter by (default: all users)",
    )
    parser.add_argument(
        "--limit", "-n",
        type=int,
        default=100,
        help="Maximum number of comments to analyze (default: 100)",
    )
    parser.add_argument(
        "--verbose", "-v",
        action="store_true",
        help="Show pos/neg/neu breakdown for each comment",
    )
    parser.add_argument(
        "--no-color",
        action="store_true",
        help="Disable colored output",
    )
    args = parser.parse_args()

    if "/" not in args.repo:
        parser.error("Repository must be in owner/repo format")

    use_color = not args.no_color and sys.stdout.isatty()

    print(f"Fetching comments from {args.repo}" + (
        f" by @{args.user}" if args.user else ""
    ) + "...")

    comments = fetch_comments(args.repo, args.user, args.limit)

    if not comments:
        print("No comments found matching the criteria.")
        sys.exit(0)

    for comment in comments:
        analyze_tone(comment)

    print_results(comments, args.verbose, use_color)


if __name__ == "__main__":
    main()
